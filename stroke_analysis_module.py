from typing import Any

import pandas  # Imports the csv data

from pandas import DataFrame
import matplotlib.pyplot as plt
import numpy as np
import seaborn




# "healthcare-dataset-stroke-data.csv"

class StrokeAnalysis:
    def __init__(self, path: str):
        self._path = path  # Path pointing to the csv file to be analyzed
        self._healthcare_dataset = pandas.read_csv(path)
        self.healthcare_array = self._healthcare_dataset.to_numpy()

    def logical_analysis(self):
        print("Performing logical analysis")

        discarding = pandas.isna(self._healthcare_dataset["bmi"])

        # Start of logical analysis. Exceptuando bmi incomplete, el resto no estÃ¡ en uso.

        self.bmi_incomplete = discarding.to_numpy() # Pacientes de los q no existen datos bmi
        self.stroked_patients = (self.healthcare_array[:, -1] == 1)
        self.diseased_patients = (self.healthcare_array[:, 4] == 1)
        self.n_stroked_patients = sum(self.stroked_patients)
        self.n_non_stroked_patients = sum(~self.stroked_patients)
        self.males = (self.healthcare_array[:, 1] == "Male") | (
                self.healthcare_array[:, 1] == "Other")  # Considered Other as males
        self.females = self.healthcare_array[:, 1] == "Female"
        self.smokers = (self.healthcare_array[:, 10] == 'smokes') | (
                self.healthcare_array[:, 10] == 'formerly smoked')
        self.stroked_smokers = (self.smokers) & (self.stroked_patients)

    def age_glucose_study(self):
        self.stroked_ages = self.healthcare_array[self.stroked_patients, 2]
        self.stroked_smokers_ages = self.healthcare_array[self.stroked_smokers, 2]
        self.ages = self.healthcare_array[:, 2]

    def data_standarization(self):
        """This function formats data for a quantitative analysis. Mean = 0 std deviation = 1 for each feature.
        It also provides the stroke (output) info in the last column"""

        selected_atributes_name = ['Age',  'hypertension', 'heart disease', 'glucose level', 'bmi','Stroke']
        # print(f' The attributes to be analyzed are {selected_atributes_name}')
        selected_atributes = [2, 3, 4, 8, 9, -1]
        simplified_health_array = self.healthcare_array[~self.bmi_incomplete, :]
        simplified_health_array = simplified_health_array[:, selected_atributes]
        feature_means = np.mean(simplified_health_array, axis=0)
        centered_simplified_array = simplified_health_array - feature_means
        feature_deviation = np.std(centered_simplified_array.astype(float), axis=0)

        standarized_array = centered_simplified_array / feature_deviation

        return standarized_array, simplified_health_array



    def PCA_and_LDA_analysis(self,standarized_array):
        print("Performing PCA and LDA analysis")
        self.complete_correlation_matrix = np.cov(standarized_array.astype(float).T)
        self.PCA_LDA_correlation_matrix =  np.cov(standarized_array[:,:-1].astype(float).T)
        print('Performed covariance matrix')

        # Computing and sorting eigenvectors and eigenvalues of the covariance matrix
        values, vectors = np.linalg.eig(self.PCA_LDA_correlation_matrix)
        eig_order = np.argsort(-values)

        self.sorted_values = values[eig_order]
        self.sorted_vectors = vectors[:,eig_order]

        # Dataset in the base generated by the eigen analysis
        eigen_dataset = np.matmul(standarized_array[:,:-1],self.sorted_vectors)

        # Nearest centroid classifier applied to the eigen dataset array

        stroked_patients_NCC = standarized_array[:, -1] > 0 # Remember that the dataset has been normalized.

        stroked_eigen_mean = np.mean(eigen_dataset[stroked_patients_NCC,:-1], axis = 0 )[:,None]
        non_stroked_eigen_mean = np.mean(eigen_dataset[~stroked_patients_NCC,:-1], axis = 0 )[:,None]

        function_weights = non_stroked_eigen_mean - stroked_eigen_mean
        function_beta = 0.5 * np.matmul(non_stroked_eigen_mean.T, non_stroked_eigen_mean) - 0.5 * np.matmul(stroked_eigen_mean.T, stroked_eigen_mean)

        # We now proceed to classify the patients with respect to the LDA method (PCA + NCC)


        self.stroked_classification = np.matmul(eigen_dataset[stroked_patients_NCC,:-1], function_weights) - function_beta
        self.non_stroked_classification = np.matmul(eigen_dataset[~stroked_patients_NCC,:-1], function_weights) - function_beta

        self.stroke_prediction_success = sum(self.stroked_classification < 0)/ len(self.stroked_classification)
        self.non_stroke_prediction_success = sum(self.non_stroked_classification > 0)/len(self.non_stroked_classification)

        classification = np.matmul(eigen_dataset[:,:-1], function_weights) - function_beta

        return classification

if __name__ == '__main__':



    d = StrokeAnalysis("healthcare-dataset-stroke-data.csv")
    d.logical_analysis()
    print(f'This is a functioning test, N of stroked patients: {d.n_stroked_patients}')

    standarized_data, simplified_data = d.data_standarization()
    classification = d.PCA_and_LDA_analysis(standarized_data)

    testing = np.append(classification, simplified_data[:,5][:,None], axis = 1)



